{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imbiotech/skbtML/blob/main/4-1.Decision_Tree_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cwm3uGpb3HkN"
      },
      "source": [
        "### `4-1.Decision Tree Model`\n",
        "* `n개의 분류 기준(Root Node)에 따라 데이터를 분류(n-depth)`하여 Target 값(Leaf)를 찾아가는 과정을 학습하는 모델\n",
        "* Root Node를 설정할 때는 `데이터의 복잡성(Entropy)의 총합이 가장 크게 줄어드는 방향`<br/>`(정보 이득이 최고가 되는 방향)`으로 설정해야 함\n",
        "    >`정보 이득이란?`: 분류 전 복잡성과 분류 후 복잡성의 차, 높을 수록 좋음\n",
        "* 설정된 Root Node에 따라 나뉘어진 데이터는 분포가 바뀜\n",
        "* 복잡성이 줄어드는 방향으로 계속 Classify를 하다가 일정 수준 이상이 되면 멈춤\n",
        "* DTM의 가장 기본적인 역할은 `Class Data(범주형 데이터)를 예측하는 것`\n",
        "* DTM을 위한 알고리즘은 다양하게 있으며 그 중 CART, C4.5, C5.0이 가장 많이 사용되며\n",
        "    <br/>대부분의 DTM 알고리즘은 다음과 같은 공통점을 지님\n",
        "    - 엔트로피를 사용\n",
        "    - 지니계수를 사용\n",
        "    - Data Classify에 사용\n",
        "    - 가장 영향력이 큰 속성을 사용\n",
        "\n",
        "\n",
        "<!-- <img src=\"클로드 샤논의 엔트로피 정의 공식\"> -->\n",
        "\n",
        "* log_{2}를 사용하는 이유는 0, 1 두 개의 bit로 나누기 위함\n",
        "* i = 물건의 종류\n",
        "    * ex) 빨간색, 파란색 등\n",
        "* n = 총 종류의 수\n",
        "    * ex) 빨간색과 파란색의 총 합\n",
        "* 확률 p = 전체 데이터에서 특정 데이터가 차지하는 비율\n",
        "    * ex) 전체 공에서 빨간색 공의 비율\n",
        "* 필요한 모든 bit(1)에 해당하는 확률을 평균한 값 = 엔트로피\n",
        "\n",
        "\n",
        "*\n",
        "\n",
        "\n",
        "* DTM에 Regression을 결합할 수 있음\n",
        "    * Leaf를 통해 Regression 진행, 분류형 뿐만 아니라 연속형 데이터에서도 사용 가능함(Regression Tree Model)\n",
        "\n",
        "* 데이터의 불순도는 엔트로피를 사용해서 평가하는데 log가 들어가기 때문에 계산 속도가 느림.\n",
        "\n",
        "    이와같은 문제의 개선을 위해 지니계수나 카이 제곱 스퀘어를 사용하기도 함\n",
        "\n",
        "    * 지니계수:\n",
        "\n",
        "        엔트로피 방법 대비 빠른 평가가 가능함\n",
        "\n",
        "    * 카이 제곱 테스트(Chi-squared Test, CST): 데이터의 독립성 검정을 위해 사용하는 지표\n",
        "\n",
        "        엔트로피 방법에서는 데이터의 불순도를 가장 낮추는 방향으로 분류한다면\n",
        "\n",
        "        카이 제곱 스퀘어에서는 데이터의 상관 관계가 가장 적어지도록 하는 방향으로 분류\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQLzLMH83HkP"
      },
      "source": [
        "---\n",
        "#### 코드블럭1\n",
        "**_Decision Tree Model 예시 코드 1 시작_**<br/>\n",
        "8*8 크기의 숫자 손글씨를 분석하여 각 이미지를 적절한 숫자로 분류하는 Decision Tree Model의 실습 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wY7AEJUs3HkP"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from sklearn import datasets, tree\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# 손글씨 데이터를 불러옴\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# 이미지를 표시함.\n",
        "for label, img in zip(digits.target[:10], digits.images[:10]):\n",
        "    plt.subplot(2, 5, label+1) # 각각의 글씨 표현을 위해 2행 5열의 subplot을 만듬\n",
        "    plt.axis('off') # 축 삭제\n",
        "    plt.imshow(img, cmap=plt.cm.gray_r, interpolation='nearest') # 이미지 표시\n",
        "    plt.title('Digit:{0}'.format(label)) # 제목 표시\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bxhk_lc03HkQ"
      },
      "outputs": [],
      "source": [
        "# 1798 개의 손글씨 데이터를 데이터(x)와 결과(y)로 나눠 저장\n",
        "images = digits.images\n",
        "labels = digits.target\n",
        "\n",
        "# 8*8 이미지 * 1797개를 64 픽셀 벡터 * 1797개로 변환\n",
        "images = images.reshape(images.shape[0], -1)\n",
        "\n",
        "# 훈련 데이터와 테스트 데이터로 분리\n",
        "n_samples = len(images) # 샘플 수\n",
        "train_size = int(n_samples * 2 / 3) # 훈련 데이터 수(전체 샘플 수의 2/3, 1198)\n",
        "classifier = tree.DecisionTreeClassifier(max_depth=3) # DCM 생성, depth는 3으로 설정\n",
        "classifier.fit(images[:train_size], labels[:train_size]) # 훈련 데이터로 모델 훈련\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "expected = labels[train_size:]\n",
        "predicted = classifier.predict(images[train_size:])\n",
        "\n",
        "# 정확도 측정\n",
        "print('Accuracy:\\n', accuracy_score(expected, predicted))\n",
        "\n",
        "# 오차 행렬(혼돈 행렬), 출력 결과가 대각선 방향으로 높은 값이 나오는 것이 좋음\n",
        "print('Confusion matrix:\\n', confusion_matrix(expected, predicted))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7sIGDwD3HkQ"
      },
      "outputs": [],
      "source": [
        "# 최적의 깊이를 찾기 위한 반복적인 fitting 실행\n",
        "score_list = []\n",
        "for depth in range(1,100):\n",
        "    dtr = tree.DecisionTreeClassifier(max_depth=depth)\n",
        "    dtr.fit(images[:train_size], labels[:train_size])\n",
        "    score_list.append(dtr.score(images[:train_size], labels[:train_size]).round(4))\n",
        "\n",
        "# 확인된 최적 깊이와 그 때 fitting score 확인\n",
        "opt_depth = score_list.index(max(score_list))+1\n",
        "\n",
        "# 최적의 깊이를 갖는 트리 모델 생성 및 훈련\n",
        "classifier_opt = tree.DecisionTreeClassifier(max_depth=opt_depth)\n",
        "classifier_opt.fit(images[:train_size], labels[:train_size])\n",
        "\n",
        "# 테스트 데이터로 예측\n",
        "expected = labels[train_size:]\n",
        "predicted = classifier_opt.predict(images[train_size:])\n",
        "\n",
        "# 정확도 측정\n",
        "print('Accuracy:\\n', accuracy_score(expected, predicted))\n",
        "\n",
        "# 오차 행렬\n",
        "print('Confusion matrix:\\n', confusion_matrix(expected, predicted))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dN3xZvFS3HkR"
      },
      "source": [
        "**_Decision Tree Model 예시 코드 1  종료_**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1PMfMQh3HkR"
      },
      "source": [
        "---\n",
        "#### 코드블럭2\n",
        "**_Decision Tree Model 예시 코드 2 시작_**<br/>\n",
        "붓꽃(Iris)의 4가지 특징 데이터를 분석하여 각 붓꽃을 적절한 종으로 분류하는 Decision Tree Model의 실습 코드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5arLbRB43HkR"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "iris = datasets.load_iris() # 붓꽃 데이터 불러오기\n",
        "\n",
        "# iris 데이터(꽃의 SL, SW, PL, PW 측정값, 꽃의 종류)의 0~2번째 데이터 출력\n",
        "iris.data[:3], iris.target[:3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUHxAQ2I3HkR"
      },
      "source": [
        "**참고**\n",
        "* Iris flower dataset은 대표적인 머신 러닝과 패턴 인식 분야에서 사용되는 유명한 데이터셋 중 하나입니다.\n",
        "* 이 데이터셋은 통계학자인 Ronald Fisher에 의해 소개되었으며, 아이리스라는 세 종류의 붓꽃에 대한 측정값을 포함하고 있습니다.\n",
        "* 전체 데이터셋은 150개의 샘플로 이루어져 있으며, 각각의 꽃마다 4개의 특성(꽃받침의 길이와 너비, 꽃잎의 길이와 너비)을 가지고 있습니다.\n",
        "* 이 데이터셋은 머신 러닝의 기초적인 예제로 많이 활용되며, 데이터 시각화, 분류, 군집화 등의 다양한 머신 러닝 기술을 학습하거나 테스트하는 데 자주 사용됩니다.\n",
        "* 데이터셋에는 아래와 같은 정보가 포함되어 있습니다:\n",
        "    * 꽃받침(sepal)의 길이(length)와 너비(width)를 측정한 값(SL, SW)\n",
        "    * 꽃잎(petal)의 길이(length)와 너비(width)를 측정한 값(PL, PW)\n",
        "    * 꽃의 종류(세 종류의 아이리스 꽃: Setosa, Versicolor, Virginica)\n",
        "\n",
        "* Iris flower data set? https://en.wikipedia.org/wiki/Iris_flower_data_set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8XGjbnov3HkS"
      },
      "outputs": [],
      "source": [
        "# Classify 형식의 DTM 생성\n",
        "clf = DecisionTreeClassifier(random_state=0)\n",
        "\n",
        "# 모델 성능 평가를 위한 교차 검증 실시 및 정확도 측정, cv=10: 교차 검증 횟수를 10회로 설정\n",
        "cross_val_score(clf, iris.data, iris.target, cv=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56FjZGpU3HkS"
      },
      "source": [
        "**교차 검증**\n",
        "\n",
        "* 교차 검증은 데이터 내에서 랜덤으로 선택된 훈련/검증 데이터로 모델을 생성하고 해당 모델을 검증하는 과정을 반복하는 것\n",
        "* 교차 검증 과정 중 0.9 이상의 값이 나온다면, 해당 데이터의 예측에 DTM을 사용해도 된다는 것을 의미\n",
        "* 교차 검증은 일반적으로 100개 이하의 데이터에서는 검증 횟수를 10회 정도로 잡으며, 데이터양이 늘어날 수록 적절히 교차 검증 횟수를 늘려 나가야 검증 효율이 올라감\n",
        "* 단, 데이터의 양이 적을 때 검증 횟수를 늘릴 경우, 모델의 성능이 저하될 수 있음"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nTNi3d5W3HkS"
      },
      "outputs": [],
      "source": [
        "# 모델 훈련 및 훈련된 모델을 사용하여 각 꽃의 [SL, SW, PL, PW] 값을 입력하면 해당 꽃의 종류를 출력\n",
        "clf.fit(iris.data, iris.target)\n",
        "clf.predict(iris.data[:3])\n",
        "\n",
        "# 예측 결과와 실제 결과 비교\n",
        "print(iris.target == clf.predict(iris.data))\n",
        "\n",
        "# 생성된 DTM의 정확도 계산\n",
        "np.mean(iris.target == clf.predict(iris.data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azPbtG7k3HkS"
      },
      "source": [
        "**_Decision Tree Model 예시 코드 2 종료_**\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}